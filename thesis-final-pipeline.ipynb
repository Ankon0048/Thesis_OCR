{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Starting of Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and PIP installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:42:19.619794Z",
     "iopub.status.busy": "2025-06-18T18:42:19.619517Z",
     "iopub.status.idle": "2025-06-18T18:43:57.602940Z",
     "shell.execute_reply": "2025-06-18T18:43:57.601780Z",
     "shell.execute_reply.started": "2025-06-18T18:42:19.619773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.156-py3-none-any.whl (1.0 MB)\n",
      "Collecting matplotlib>=3.3.0\n",
      "  Downloading matplotlib-3.10.3-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Collecting opencv-python>=4.6.0\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Collecting requests>=2.23.0\n",
      "  Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Collecting tqdm>=4.64.0\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting pyyaml>=5.3.1\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Collecting torch>=1.8.0\n",
      "  Downloading torch-2.7.1-cp310-cp310-win_amd64.whl (216.1 MB)\n",
      "Collecting numpy>=1.23.0\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Collecting pillow>=7.1.2\n",
      "  Using cached pillow-11.2.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "Collecting torchvision>=0.9.0\n",
      "  Downloading torchvision-0.22.1-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "Collecting pandas>=1.1.4\n",
      "  Using cached pandas-2.3.0-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "Collecting ultralytics-thop>=2.0.0\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Collecting scipy>=1.4.1\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.58.4-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl (105 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Installing collected packages: mpmath, MarkupSafe, sympy, numpy, networkx, jinja2, fsspec, filelock, urllib3, tzdata, torch, pytz, pyparsing, pillow, kiwisolver, idna, fonttools, cycler, contourpy, charset-normalizer, certifi, ultralytics-thop, tqdm, torchvision, scipy, requests, pyyaml, py-cpuinfo, pandas, opencv-python, matplotlib, ultralytics\n",
      "Successfully installed MarkupSafe-3.0.2 certifi-2025.6.15 charset-normalizer-3.4.2 contourpy-1.3.2 cycler-0.12.1 filelock-3.18.0 fonttools-4.58.4 fsspec-2025.5.1 idna-3.10 jinja2-3.1.6 kiwisolver-1.4.8 matplotlib-3.10.3 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 opencv-python-4.11.0.86 pandas-2.3.0 pillow-11.2.1 py-cpuinfo-9.0.0 pyparsing-3.2.3 pytz-2025.2 pyyaml-6.0.2 requests-2.32.4 scipy-1.15.3 sympy-1.14.0 torch-2.7.1 torchvision-0.22.1 tqdm-4.67.1 tzdata-2025.2 ultralytics-8.3.156 ultralytics-thop-2.0.14 urllib3-2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:43:57.605567Z",
     "iopub.status.busy": "2025-06-18T18:43:57.605201Z",
     "iopub.status.idle": "2025-06-18T18:43:58.699973Z",
     "shell.execute_reply": "2025-06-18T18:43:58.698794Z",
     "shell.execute_reply.started": "2025-06-18T18:43:57.605532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "from scipy.ndimage import binary_closing\n",
    "import secrets      # cryptographically‑secure RNG\n",
    "import base64       # for compact ASCII/“number + letter” output\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:46:16.073573Z",
     "iopub.status.busy": "2025-06-18T18:46:16.072723Z",
     "iopub.status.idle": "2025-06-18T18:46:16.080606Z",
     "shell.execute_reply": "2025-06-18T18:46:16.079252Z",
     "shell.execute_reply.started": "2025-06-18T18:46:16.073520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Input image\n",
    "image_path = \"kaggle/input/tests/a01-000x.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:46:16.215000Z",
     "iopub.status.busy": "2025-06-18T18:46:16.214644Z",
     "iopub.status.idle": "2025-06-18T18:46:23.776669Z",
     "shell.execute_reply": "2025-06-18T18:46:23.775812Z",
     "shell.execute_reply.started": "2025-06-18T18:46:16.214974Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Ultralytics settings reset to default values. This may be due to a possible problem with your settings or a recent ultralytics package update. \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\User\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"kaggle/input/weights/last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:46:28.313114Z",
     "iopub.status.busy": "2025-06-18T18:46:28.312614Z",
     "iopub.status.idle": "2025-06-18T18:46:28.322862Z",
     "shell.execute_reply": "2025-06-18T18:46:28.321607Z",
     "shell.execute_reply.started": "2025-06-18T18:46:28.313087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def seperate_handwritten_printed_using_yolo(image_path, folder_name):\n",
    "    results = model([image_path])  # assuming `model` is already defined and loaded\n",
    "    image = cv2.imread(image_path)\n",
    "    base_name = os.path.basename(image_path)\n",
    "\n",
    "    base_crop_folder = \"cropped_outputs\"\n",
    "    base_graph_folder = \"graph_outputs\"\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        cls = boxes.cls.cpu().numpy()\n",
    "        xyxy = boxes.xyxy.cpu().numpy()\n",
    "\n",
    "        class9_boxes = [box for i, box in enumerate(xyxy) if cls[i] == 9]\n",
    "\n",
    "        def ensure_and_save_crop(box, root_folder):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cropped = image[y1:y2, x1:x2]\n",
    "            subfolder = os.path.join(folder_name, root_folder)\n",
    "            os.makedirs(subfolder, exist_ok=True)\n",
    "            filename = f\"{uuid.uuid4().hex}.jpg\"\n",
    "            print(cv2.imwrite(os.path.join(subfolder, filename), cropped))\n",
    "\n",
    "        # Save all class 9 cropped regions\n",
    "        for box in class9_boxes:\n",
    "            ensure_and_save_crop(box, base_crop_folder)\n",
    "\n",
    "        # Save image with detection graph\n",
    "        graph = result.plot()\n",
    "        graph_folder = os.path.join(folder_name, base_graph_folder)\n",
    "        os.makedirs(graph_folder, exist_ok=True)\n",
    "        print(cv2.imwrite(os.path.join(graph_folder, base_name), graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:46:30.611963Z",
     "iopub.status.busy": "2025-06-18T18:46:30.611608Z",
     "iopub.status.idle": "2025-06-18T18:46:36.780968Z",
     "shell.execute_reply": "2025-06-18T18:46:36.779948Z",
     "shell.execute_reply.started": "2025-06-18T18:46:30.611937Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 192x640 2 Section-headers, 1 Text, 55.0ms\n",
      "Speed: 1.4ms preprocess, 55.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "seperate_handwritten_printed_using_yolo(image_path, \"kaggle/output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting lines from the detected image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:53:01.267462Z",
     "iopub.status.busy": "2025-06-18T18:53:01.266162Z",
     "iopub.status.idle": "2025-06-18T18:53:01.272664Z",
     "shell.execute_reply": "2025-06-18T18:53:01.271629Z",
     "shell.execute_reply.started": "2025-06-18T18:53:01.267300Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Update your base directories\n",
    "base_input_dir = r\"kaggle/output/cropped_outputs\"\n",
    "base_output_printed = r\"kaggle/output/cropped_outputs_line\"\n",
    "base_graph_folder = r\"kaggle/output/line_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:53:03.039578Z",
     "iopub.status.busy": "2025-06-18T18:53:03.039226Z",
     "iopub.status.idle": "2025-06-18T18:53:03.063803Z",
     "shell.execute_reply": "2025-06-18T18:53:03.062914Z",
     "shell.execute_reply.started": "2025-06-18T18:53:03.039555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "from scipy.ndimage import binary_closing\n",
    "\n",
    "def auto_savgol_smooth(profile, polyorder=2, spacing_factor=None,\n",
    "                       plot=True, plot_title=\"\", save_path=None,\n",
    "                       show_thresholds=False, high_thresh=None, low_thresh=None):\n",
    "    \n",
    "    peaks, _ = find_peaks(profile, distance=8)\n",
    "    if len(peaks) < 2:\n",
    "        raise ValueError(\"Not enough peaks detected to estimate line spacing.\")\n",
    "\n",
    "    diffs = np.diff(peaks)\n",
    "    eps = 1e-9\n",
    "    weights = 1.0 / (diffs + eps)\n",
    "    avg_spacing = int(np.round(np.sum(weights * diffs) / np.sum(weights)))\n",
    "\n",
    "    # Dynamically estimate spacing_factor if not provided\n",
    "    if spacing_factor is None:\n",
    "        spacing_factor = min(max(1.2, avg_spacing / 20), 2.0)\n",
    "\n",
    "    window_length = int(spacing_factor * avg_spacing)\n",
    "    if window_length % 2 == 0:\n",
    "        window_length += 1\n",
    "    window_length = max(window_length, polyorder + 4)\n",
    "    window_length = min(window_length,\n",
    "                        len(profile) - 1 if len(profile) % 2 else len(profile) - 2)\n",
    "\n",
    "    smoothed = savgol_filter(profile, window_length=window_length, polyorder=polyorder)\n",
    "\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(14, 5))\n",
    "        plt.plot(profile, label=\"Original\", color=\"orange\", alpha=0.6)\n",
    "        plt.plot(smoothed, label=f\"Smoothed (window={window_length})\", color=\"blue\")\n",
    "        plt.plot(peaks, profile[peaks], \"rx\", label=\"Detected Peaks\")\n",
    "\n",
    "        if show_thresholds:\n",
    "            if high_thresh is not None:\n",
    "                plt.axhline(y=high_thresh, color=\"red\", linestyle=\"--\", label=f\"High Thresh = {high_thresh:.2f}\")\n",
    "            if low_thresh is not None:\n",
    "                plt.axhline(y=low_thresh, color=\"green\", linestyle=\"--\", label=f\"Low Thresh = {low_thresh:.2f}\")\n",
    "\n",
    "        plt.title(plot_title or \"Savitzky-Golay smoothing\")\n",
    "        plt.xlabel(\"Row Index\")\n",
    "        plt.ylabel(\"Sum of Pixel Intensities\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        if save_path is not None:\n",
    "            fig.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "    return smoothed, spacing_factor\n",
    "\n",
    "\n",
    "\n",
    "def calculate_projection_profile_and_crop_lines_with_lines(image_path, folder_name):\n",
    "    base_name = os.path.basename(image_path)\n",
    "    image_name_no_ext = os.path.splitext(base_name)[0]\n",
    "\n",
    "    subfolder_graph = os.path.join(base_graph_folder, folder_name)\n",
    "    os.makedirs(subfolder_graph, exist_ok=True)\n",
    "    output_path = os.path.join(subfolder_graph, f\"{base_name}\")\n",
    "\n",
    "    image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image {image_path}\")\n",
    "        return\n",
    "\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    horizontal_projection = np.sum(binary_image, axis=1)\n",
    "\n",
    "    smoothed, spacing_factor = auto_savgol_smooth(\n",
    "        horizontal_projection,\n",
    "        save_path=output_path,\n",
    "        plot=True,\n",
    "        show_thresholds=True\n",
    "    )\n",
    "\n",
    "    # === Dynamic Thresholds ===\n",
    "    Q1 = np.percentile(smoothed, 25)\n",
    "    Q3 = np.percentile(smoothed, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    mean_val = np.mean(smoothed)\n",
    "    min_val = np.min(smoothed)\n",
    "    max_val = np.max(smoothed)\n",
    "\n",
    "    iqr_low = Q1 + 0.2 * IQR\n",
    "    iqr_high = iqr_low + 0.25 * IQR\n",
    "    mean_low = mean_val * 0.25\n",
    "    mean_high = mean_val * 0.6\n",
    "    scaled_low = min_val + 0.1 * (max_val - min_val)\n",
    "    scaled_high = min_val + 0.35 * (max_val - min_val)\n",
    "\n",
    "    low_thresh = np.median([iqr_low, mean_low, scaled_low])\n",
    "    high_thresh = np.median([iqr_high, mean_high, scaled_high])\n",
    "\n",
    "    # Re-plot with thresholds\n",
    "    smoothed, _ = auto_savgol_smooth(\n",
    "        horizontal_projection,\n",
    "        spacing_factor=spacing_factor,\n",
    "        save_path=output_path,\n",
    "        plot=True,\n",
    "        show_thresholds=True,\n",
    "        high_thresh=high_thresh,\n",
    "        low_thresh=low_thresh\n",
    "    )\n",
    "\n",
    "    # === Line Detection with Relaxed High Threshold at Bottom ===\n",
    "    line_ranges = []\n",
    "    is_in_line = False\n",
    "    relaxed_zone = int(0.8 * len(smoothed))\n",
    "\n",
    "    for row, value in enumerate(smoothed):\n",
    "        current_high = high_thresh\n",
    "        if row > relaxed_zone:\n",
    "            current_high = high_thresh * 0.7  # relax threshold in bottom zone\n",
    "\n",
    "        if value > current_high and not is_in_line:\n",
    "            start_row = row\n",
    "            is_in_line = True\n",
    "        elif value < low_thresh and is_in_line:\n",
    "            end_row = row\n",
    "            line_ranges.append((start_row, end_row))\n",
    "            is_in_line = False\n",
    "\n",
    "    if is_in_line:\n",
    "        line_ranges.append((start_row, len(smoothed)))\n",
    "\n",
    "    # === Fallback: Recover Missed Final Line ===\n",
    "    last_line_margin = int(len(smoothed) * 0.17)\n",
    "    end_threshold = len(smoothed) - last_line_margin\n",
    "    last_part_vals = smoothed[-last_line_margin:]\n",
    "\n",
    "    if all(end < end_threshold for _, end in line_ranges):\n",
    "        if np.max(last_part_vals) > low_thresh:\n",
    "            fallback_start = end_threshold\n",
    "            line_ranges.append((fallback_start, len(smoothed)))\n",
    "\n",
    "    # === Refine Borders ===\n",
    "    if line_ranges:\n",
    "        line_ranges[0] = (max(0, line_ranges[0][0] - 5), line_ranges[0][1])\n",
    "        line_ranges[-1] = (line_ranges[-1][0], min(image.shape[0], line_ranges[-1][1] + 5))\n",
    "\n",
    "    for i in range(1, len(line_ranges)):\n",
    "        temp = (line_ranges[i - 1][1] + line_ranges[i][0]) // 2\n",
    "        line_ranges[i - 1] = (line_ranges[i - 1][0], temp)\n",
    "        line_ranges[i] = (temp, line_ranges[i][1])\n",
    "\n",
    "    line_ranges = sorted(line_ranges, key=lambda x: x[0])\n",
    "\n",
    "    # === Save Cropped Lines ===\n",
    "    subfolder_output = os.path.join(base_output_printed, folder_name, image_name_no_ext)\n",
    "    os.makedirs(subfolder_output, exist_ok=True)\n",
    "\n",
    "    for idx, (start, end) in enumerate(line_ranges, 1):\n",
    "        cropped_line = image[start:end, :]\n",
    "        save_path = os.path.join(subfolder_output, f\"{idx}.png\")\n",
    "        print(f'save_path = {save_path}')\n",
    "        cv2.imwrite(save_path, cropped_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:53:08.238688Z",
     "iopub.status.busy": "2025-06-18T18:53:08.238265Z",
     "iopub.status.idle": "2025-06-18T18:53:08.245716Z",
     "shell.execute_reply": "2025-06-18T18:53:08.244438Z",
     "shell.execute_reply.started": "2025-06-18T18:53:08.238662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# === Batch processor ===\n",
    "def process_all_images():\n",
    "    for root, dirs, files in os.walk(base_input_dir):\n",
    "        image_files = sorted(\n",
    "            [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "        )\n",
    "        for file in image_files:\n",
    "            image_path = os.path.join(root, file)\n",
    "            folder_name = os.path.basename(root)\n",
    "            try:\n",
    "                calculate_projection_profile_and_crop_lines_with_lines(image_path, folder_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:53:09.632277Z",
     "iopub.status.busy": "2025-06-18T18:53:09.631912Z",
     "iopub.status.idle": "2025-06-18T18:53:10.138098Z",
     "shell.execute_reply": "2025-06-18T18:53:10.137252Z",
     "shell.execute_reply.started": "2025-06-18T18:53:09.632248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_path = kaggle/output/cropped_outputs_line\\cropped_outputs\\ccb78bea7c4848f0b41dc297f7fbda07\\1.png\n",
      "save_path = kaggle/output/cropped_outputs_line\\cropped_outputs\\ccb78bea7c4848f0b41dc297f7fbda07\\2.png\n",
      "save_path = kaggle/output/cropped_outputs_line\\cropped_outputs\\ccb78bea7c4848f0b41dc297f7fbda07\\3.png\n",
      "save_path = kaggle/output/cropped_outputs_line\\cropped_outputs\\ccb78bea7c4848f0b41dc297f7fbda07\\4.png\n"
     ]
    }
   ],
   "source": [
    "process_all_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting whether Image is handwritten or printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T17:54:55.471033Z",
     "iopub.status.busy": "2025-06-18T17:54:55.470678Z",
     "iopub.status.idle": "2025-06-18T17:54:55.493355Z",
     "shell.execute_reply": "2025-06-18T17:54:55.492238Z",
     "shell.execute_reply.started": "2025-06-18T17:54:55.471010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the same model class\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Create model and load weights\n",
    "model = SimpleCNN().to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"kaggle/input/weights/final_model_weights_HvP.pth\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# Test transforms\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T17:55:53.128025Z",
     "iopub.status.busy": "2025-06-18T17:55:53.127395Z",
     "iopub.status.idle": "2025-06-18T17:55:53.138114Z",
     "shell.execute_reply": "2025-06-18T17:55:53.136599Z",
     "shell.execute_reply.started": "2025-06-18T17:55:53.127992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# --- Load and preprocess the image ---\n",
    "def predict_HvP(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = test_transform(image).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
    "    \n",
    "    # --- Make prediction ---\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        predicted_class = output.argmax(1).item()\n",
    "    \n",
    "    # --- Map class index to class name ---\n",
    "    class_names = [\"handwritten\", \"printed\"]  # Get class names from dataset\n",
    "    print(f\"Predicted class label: {class_names[predicted_class]}\")\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting text from image using TrOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T17:56:11.425455Z",
     "iopub.status.busy": "2025-06-18T17:56:11.424393Z",
     "iopub.status.idle": "2025-06-18T17:56:11.433136Z",
     "shell.execute_reply": "2025-06-18T17:56:11.431961Z",
     "shell.execute_reply.started": "2025-06-18T17:56:11.425423Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--microsoft--trocr-base-printed. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--microsoft--trocr-large-handwritten. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import os\n",
    "\n",
    "# Load models and processors only once\n",
    "hand_written_model_id = \"microsoft/trocr-large-handwritten\"\n",
    "printed_model_id = \"microsoft/trocr-base-printed\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "# Load both models and processors once\n",
    "printed_processor = TrOCRProcessor.from_pretrained(printed_model_id)\n",
    "printed_model = VisionEncoderDecoderModel.from_pretrained(printed_model_id).to(device)\n",
    "\n",
    "handwritten_processor = TrOCRProcessor.from_pretrained(hand_written_model_id)\n",
    "handwritten_model = VisionEncoderDecoderModel.from_pretrained(hand_written_model_id).to(device)\n",
    "\n",
    "# OCR runner\n",
    "def run_trOCR(model, processor, image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    generated_ids = model.generate(pixel_values, max_new_tokens=1000)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(f\"{os.path.basename(image_path)} -> {generated_text}\")\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Prediction for the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:10:45.729089Z",
     "iopub.status.busy": "2025-06-18T18:10:45.728734Z",
     "iopub.status.idle": "2025-06-18T18:10:45.736317Z",
     "shell.execute_reply": "2025-06-18T18:10:45.735220Z",
     "shell.execute_reply.started": "2025-06-18T18:10:45.729062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Path to input images\n",
    "folder_dir = \"kaggle/output/cropped_outputs_line/cropped_outputs/\"\n",
    "input_dir = os.path.join(folder_dir,os.listdir(folder_dir)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:04:08.236267Z",
     "iopub.status.busy": "2025-06-18T18:04:08.235899Z",
     "iopub.status.idle": "2025-06-18T18:05:03.402334Z",
     "shell.execute_reply": "2025-06-18T18:05:03.401429Z",
     "shell.execute_reply.started": "2025-06-18T18:04:08.236241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: printed\n",
      "1.png -> A MOVE TO STOP MR. GAITSKELL FROM DOMINATING ANY MAKE LABOR LIFE IS TO\n",
      "Predicted class label: printed\n",
      "2.png -> BE MADE AT A MEETING OF LABOUR OM PS TOMORROW. MR. MIDHAEL FOOT HAS PUT DOWN\n",
      "Predicted class label: printed\n",
      "3.png -> A RESOLUTION ON THE SUBJECT AND BE IS TO BE BACKED BY MR. WILL GRIFITHS, OM P FOR\n",
      "Predicted class label: printed\n",
      "4.png -> MANCHASTER EXCHANGE.COME AGAIN PERMAS AND BEAUTIONS\n"
     ]
    }
   ],
   "source": [
    "# Collect image file paths\n",
    "file_paths = [\n",
    "    os.path.join(input_dir, filename)\n",
    "    for filename in sorted(os.listdir(input_dir))  # sort if needed\n",
    "    if os.path.isfile(os.path.join(input_dir, filename))\n",
    "]\n",
    "\n",
    "# Loop through and run OCR\n",
    "for path in file_paths:\n",
    "    if predict_HvP(path) == 1:\n",
    "        run_trOCR(printed_model, printed_processor, path)\n",
    "    else:\n",
    "        run_trOCR(handwritten_model, handwritten_processor, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7683776,
     "sourceId": 12198063,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7683938,
     "sourceId": 12209503,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7691437,
     "sourceId": 12209516,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
